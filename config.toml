# ---------------------------
# Настройки корпусов данных
# ---------------------------

[datasets.meld]
base_dir = "E:/MELD"
csv_path = "{base_dir}/meld_{split}_labels.csv"
wav_dir  = "{base_dir}/wavs/{split}"

[datasets.resd]
base_dir = "E:/RESD"
csv_path = "{base_dir}/resd_{split}_labels.csv"
wav_dir  = "{base_dir}/wavs/{split}"


# ---------------------------
# Список модальностей и эмоций
# ---------------------------
modalities = ["audio"]
# emotion_columns = ["neutral", "happy", "sad", "anger", "surprise", "disgust", "fear"]
emotion_columns = ["anger", "disgust", "fear", "happy", "neutral", "sad", "surprise"]

# ---------------------------
# DataLoader параметры
# ---------------------------
[dataloader]
batch_size = 8
num_workers = 0
shuffle = true

# ---------------------------
# Аудио
# ---------------------------
[audio]
sample_rate = 16000           # Целевая частота дискретизации
wav_length = 4                # Целевая длина (в секундах) для аудио

[audio_saving]
save_processed_audio = false
audio_output_dir = "{base_dir}\\output_wavs"

# ---------------------------
# Whisper и текст
# ---------------------------
[text]
# Если "csv", то мы стараемся брать текст из CSV, если там есть
# (поле text_column). Если нет - тогда Whisper (если нужно).
source = "csv"
text_column = "text"
whisper_model = "base"

# Указываем, где запускать Whisper: "cuda" (GPU) или "cpu"
whisper_device = "cuda"

# Если для dev/test в CSV нет текста, нужно ли всё же вызывать Whisper?
use_whisper_for_nontrain_if_no_text = true

# ---------------------------
# Параметры для тренировки
# ---------------------------
[train]
# Если указать random_seed, мы фиксируем seed => воспроизводимые результаты
random_seed = 42 #  <=0 - рандомная выборка будет каждый раз
subset_size = 20 # Если subset_size = 0 или subset_size не указан, значит используем весь датасет без ограничений.
merge_probability = 0 # процент семплирования коротких файлов.
hidden_dim = 128 # число скрытых состояний в трансформере
hidden_dim_gated = 128 # число скрытых состояния в gated
num_transformer_heads = 2 # число голов в трансформере
num_graph_heads = 2 # число голов в графе
tr_layer_number = 1 # число слоев в трансформере
mode = 'mean' # статистический пуллинг контекстных признаков
positional_encoding = false # примерение позиционного кодирования признаков
dropout = 0 # процент отсева нейронов
out_features = 128 # число классификационных признаков
lr = 1e-4 # скорость обучения
num_epochs = 2 # число эпох обучения
model_name = "BiFormer" # имя класса модели BiGraphFormer BiFormer BiGatedGraphFormer
max_patience = 10 # Параметр ранней остановки обучения
save_prepared_data = true # Сохранить эмбеддинги
save_feature_path = './features/' # Путь для сохранения эмбеддингов
search_type = "none"  # greedy или "exhaustive", или "none"

[embeddings]
# audio_model = "amiriparian/ExHuBERT"  # Hugging Face имя модели для аудио
audio_model = "audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim"  # Hugging Face имя модели для аудио
audio_classifier_checkpoint = "best_audio_model.pt"
text_classifier_checkpoint = "best_text_model.pth"
text_model = "jinaai/jina-embeddings-v3"  # Hugging Face имя модели для текста
# вынести в конфиг
audio_embedding_dim = 256  # размерность аудио-эмбеддинга
text_embedding_dim = 1024   # размерность текст-эмбеддинга
emb_normalize = false  # нормализовать ли вектор L2-нормой

# audio_pooling = "mean"        # "mean", "cls", "max", "min", "last", "attention"
# text_pooling = "cls"          # "mean", "cls", "max", "min", "last", "sum", "attention"

max_tokens = 95         # ограничение на длину текста (токенов) при токенизации
max_audio_frames = 64000 # ограничение на длину аудио (семплов) до усечения

device = "cuda"          # "cuda" или "cpu", куда грузить модель
