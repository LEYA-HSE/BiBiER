# dia_tts_wrapper.py

import os
import time
import logging
import torch
import soundfile as sf
import numpy as np
from dia.model import Dia


class DiaTTSWrapper:
    def __init__(self, model_name="nari-labs/Dia-1.6B", device="cuda", dtype="float16"):
        """
        :param model_name: HuggingFace ID –º–æ–¥–µ–ª–∏ DIA-TTS.
        :param device: "cuda" –∏–ª–∏ "cpu".
        :param dtype: float16 | bfloat16 | float32 ‚Äî —ç–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏ –∏ —É—Å–∫–æ—Ä–µ–Ω–∏–µ.
        """
        self.device = device
        self.sr = 44100  # –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è Dia

        logging.info(f"[DiaTTS] –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ {model_name} –Ω–∞ {device} (dtype={dtype})")
        self.model = Dia.from_pretrained(
            model_name,
            device=device,
            compute_dtype=dtype
        )

    def generate_audio_from_text(self, text: str, paralinguistic: str = "", max_duration: float = None) -> torch.Tensor:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–π –º–µ—Ç–∫–æ–π —ç–º–æ—Ü–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'laughs').
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–Ω–∑–æ—Ä (1, num_samples).
        """
        try:
            if paralinguistic:
                clean = paralinguistic.strip("()").lower()
                text = f"{text} ({clean})"

            audio_np = self.model.generate(
                text,
                use_torch_compile=False,
                verbose=False
            )

            wf = torch.from_numpy(audio_np).float().unsqueeze(0)

            if max_duration:
                max_samples = int(self.sr * max_duration)
                wf = wf[:, :max_samples]

            return wf

        except Exception as e:
            logging.error(f"[DiaTTS] –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ: {e}")
            return torch.zeros(1, self.sr)

    def generate_and_save_audio(self, text: str, paralinguistic: str = "", out_dir="tts_outputs", filename_prefix="tts", max_duration: float = None) -> torch.Tensor:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ WAV-–∞—É–¥–∏–æ.
        """
        os.makedirs(out_dir, exist_ok=True)
        wf = self.generate_audio_from_text(text, paralinguistic, max_duration)
        np_wf = wf.squeeze().cpu().numpy()

        timestr = time.strftime("%Y%m%d_%H%M%S")
        filename = f"{filename_prefix}_{timestr}.wav"
        out_path = os.path.join(out_dir, filename)

        sf.write(out_path, np_wf, self.sr)
        logging.info(f"[DiaTTS] üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∞—É–¥–∏–æ: {out_path}")
        return wf

    def get_sample_rate(self):
        return self.sr
